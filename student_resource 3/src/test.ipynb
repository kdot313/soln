{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b70b34e",
   "metadata": {},
   "source": [
    "### Basic library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719d15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911e33",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3136aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebd689",
   "metadata": {},
   "source": [
    "### Run Sanity check using src/sanity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81bb3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing successfull for file: ../dataset/sample_test_out.csv\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa79459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid unit [lbs] found in 6.75 lbs. Allowed units: {'cup', 'milligram', 'millimetre', 'microlitre', 'ounce', 'watt', 'volt', 'fluid ounce', 'gram', 'pint', 'kilovolt', 'millivolt', 'centilitre', 'cubic foot', 'pound', 'imperial gallon', 'metre', 'kilogram', 'cubic inch', 'microgram', 'quart', 'yard', 'litre', 'inch', 'gallon', 'centimetre', 'decilitre', 'millilitre', 'kilowatt', 'ton', 'foot'}\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out_fail.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe930a8",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d1aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_images\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb57b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Solutions/student_resource 3\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872b3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Solutions/student_resource 3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c38a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train data\n",
    "train_data = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0a7a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_name\n",
       "item_weight                      102786\n",
       "depth                             45127\n",
       "width                             44183\n",
       "height                            43597\n",
       "voltage                            9466\n",
       "wattage                            7755\n",
       "item_volume                        7682\n",
       "maximum_weight_recommendation      3263\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"entity_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3feb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stratified splitter (Stratify by 'entity_name')\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7c4e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified sampling based on the 'entity_name' column\n",
    "for train_idx, sample_idx in splitter.split(train_data, train_data['entity_name']):\n",
    "    stratified_sample = train_data.iloc[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71165bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity_name\n",
       "item_weight                      20\n",
       "depth                             9\n",
       "width                             8\n",
       "height                            8\n",
       "voltage                           2\n",
       "item_volume                       1\n",
       "wattage                           1\n",
       "maximum_weight_recommendation     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_sample[\"entity_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7643e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stratified sample to a new CSV file\n",
    "stratified_sample.to_csv('stratified_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93f8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder where images will be downloaded\n",
    "download_folder = 'downloaded_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7d815f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "from utils import download_images, parse_string, common_mistake\n",
    "import constants\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from functools import partial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eead5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocessing function for images\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply thresholding\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        # Apply median blur to remove noise\n",
    "        processed_image = cv2.medianBlur(thresh, 3)\n",
    "        return processed_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f737fd6",
   "metadata": {},
   "source": [
    "## Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97e2822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_pytesseract(image_path):\n",
    "    try:\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        # Convert processed image to PIL format for Pytesseract\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        text = pytesseract.image_to_string(pil_image)\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"OCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d844289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_pytesseract(stratified_sample_file, download_folder, output_file):\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    print(\"Extracting text using Pytesseract...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_pytesseract(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up images after extraction\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b3552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 151.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using Pytesseract...\n",
      "Results saved to output_pytesseract.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "process_images_pytesseract(\"stratified_sample.csv\", \"downloaded_images\", \"output_pytesseract.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e244de",
   "metadata": {},
   "source": [
    "## Pytesseract without PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bebf3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:19<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raw text from images...\n",
      "Updated stratified_sample.csv with extracted text.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import download_images\n",
    "\n",
    "# Step 1: OCR extraction without any preprocessing\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        # Directly use Pytesseract on the raw image\n",
    "        text = pytesseract.image_to_string(Image.open(image_path))\n",
    "        return text.strip()  # Return the extracted text without leading/trailing spaces\n",
    "    except Exception as e:\n",
    "        print(f\"OCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Step 2: Process each row to download the image and extract text\n",
    "def process_row(row, download_folder):\n",
    "    image_link = row['image_link']\n",
    "    # Extract the image name from the image link\n",
    "    image_name = os.path.basename(image_link)\n",
    "    # Set the path where the image was saved after download\n",
    "    image_path = os.path.join(download_folder, image_name)\n",
    "    \n",
    "    # Extract raw text from the image using Pytesseract OCR\n",
    "    extracted_text = extract_text_from_image(image_path)\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "# Step 3: Download images, extract text, and clean up images\n",
    "def process_images_and_extract_text(stratified_sample_file, download_folder):\n",
    "    # Load the stratified sample dataset from the CSV file\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    \n",
    "    # Step 3.1: Download images using the URLs in the image_link column\n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    # Step 3.2: Loop through each row to extract text from images\n",
    "    print(\"Extracting raw text from images...\")\n",
    "    df['Extracted'] = df.apply(lambda row: process_row(row, download_folder), axis=1)\n",
    "    \n",
    "    # Step 3.3: Clean up images from the local folder after extraction\n",
    "    for file in os.listdir(download_folder):\n",
    "        file_path = os.path.join(download_folder, file)\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "    \n",
    "    # Save the updated DataFrame back to the original stratified_sample.csv\n",
    "    df.to_csv(stratified_sample_file, index=False)\n",
    "    print(f\"Updated {stratified_sample_file} with extracted text.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stratified_sample_file = \"stratified_sample.csv\"  # Your file name for the dataset\n",
    "    download_folder = \"downloaded_images\"  # Folder to store downloaded images\n",
    "    \n",
    "    # Process images, extract text, and update stratified_sample.csv\n",
    "    process_images_and_extract_text(stratified_sample_file, download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810e4ee",
   "metadata": {},
   "source": [
    "## Easy-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e92f1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "199b0ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "/workspaces/Solutions/env/lib/python3.10/site-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/workspaces/Solutions/env/lib/python3.10/site-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the EasyOCR reader once\n",
    "reader_easyocr = easyocr.Reader(['en'], detector='dbnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb92940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_easyocr(image_path):\n",
    "    try:\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        # Use EasyOCR for text extraction\n",
    "        result = reader_easyocr.readtext(preprocessed_image, detail=0, batch_size=32)\n",
    "        return ' '.join(result).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"EasyOCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6147a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_easyocr(stratified_sample_file, download_folder, output_file):\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    print(\"Extracting text using EasyOCR...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_easyocr(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up images after extraction\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5744118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 152.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using EasyOCR...\n",
      "Results saved to output_easyocr.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "process_images_easyocr(\"stratified_sample.csv\", \"downloaded_images\", \"output_easyocr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80764a5",
   "metadata": {},
   "source": [
    "## Keras-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4ad0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b91fba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff08075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 14:41:20.378290: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 14:41:20.382330: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 14:41:20.393947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 14:41:20.405401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 14:41:20.409396: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 14:41:20.419704: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 14:41:21.314544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13267650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/codespace/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /home/codespace/.keras-ocr/crnn_kurapan.h5\n",
      "Downloading /home/codespace/.keras-ocr/crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Keras-OCR pipeline once\n",
    "pipeline_kerasocr = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa4454fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_kerasocr(image_path):\n",
    "    try:\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        # Keras-OCR needs the image in RGB format\n",
    "        image_rgb = cv2.cvtColor(preprocessed_image, cv2.COLOR_GRAY2RGB)\n",
    "        prediction_groups = pipeline_kerasocr.recognize([image_rgb])\n",
    "        extracted_text = ' '.join([text for text, _ in prediction_groups[0]])\n",
    "        return extracted_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"KerasOCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0299ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_kerasocr(stratified_sample_file, download_folder, output_file):\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    print(\"Extracting text using KerasOCR...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_kerasocr(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up images after extraction\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02eb8084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 165.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using KerasOCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 14:43:14.089716: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 48096048 exceeds 10% of free system memory.\n",
      "2024-09-14 14:43:14.134769: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 48096048 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /workspaces/Solutions/env/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 14:43:14.562991: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1026049024 exceeds 10% of free system memory.\n",
      "2024-09-14 14:43:15.161781: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1026049024 exceeds 10% of free system memory.\n",
      "2024-09-14 14:43:17.249428: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 256512256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 897ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 690ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step\n",
      "Results saved to output_kerasocr.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "process_images_kerasocr(\"stratified_sample.csv\", \"downloaded_images\", \"output_kerasocr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc55900",
   "metadata": {},
   "source": [
    "## Paddle-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17fc8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PaddleOCR'...\n",
      "remote: Enumerating objects: 51247, done.\u001b[K\n",
      "remote: Counting objects: 100% (2471/2471), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1190/1190), done.\u001b[K\n",
      "remote: Total 51247 (delta 1283), reused 2259 (delta 1234), pack-reused 48776 (from 1)\u001b[K\n",
      "Receiving objects: 100% (51247/51247), 385.66 MiB | 19.71 MiB/s, done.\n",
      "Resolving deltas: 100% (35672/35672), done.\n",
      "Updating files: 100% (2390/2390), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PaddlePaddle/PaddleOCR.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62947885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f326e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/09/14 11:10:49] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/codespace/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/codespace/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/workspaces/Solutions/env/lib/python3.10/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/codespace/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PaddleOCR model once\n",
    "ocr_paddleocr = PaddleOCR(use_angle_cls=True, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04263ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_paddleocr(image_path):\n",
    "    try:\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        # PaddleOCR requires the image in file path format\n",
    "        result = ocr_paddleocr.ocr(image_path)\n",
    "        extracted_text = ' '.join([line[1][0] for line in result[0]])\n",
    "        return extracted_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"PaddleOCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d74bb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_paddleocr(stratified_sample_file, download_folder, output_file):\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    print(\"Extracting text using PaddleOCR...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_paddleocr(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up images after extraction\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcc9cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using PaddleOCR...\n",
      "[2024/09/14 11:10:56] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.24773788452148438\n",
      "[2024/09/14 11:10:56] ppocr DEBUG: cls num  : 2, elapsed : 0.028303861618041992\n",
      "[2024/09/14 11:10:56] ppocr DEBUG: rec_res num  : 2, elapsed : 0.09077668190002441\n",
      "[2024/09/14 11:10:56] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.16480779647827148\n",
      "[2024/09/14 11:10:56] ppocr DEBUG: cls num  : 5, elapsed : 0.024401426315307617\n",
      "[2024/09/14 11:10:57] ppocr DEBUG: rec_res num  : 5, elapsed : 0.16092491149902344\n",
      "[2024/09/14 11:10:57] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.16276264190673828\n",
      "[2024/09/14 11:10:57] ppocr DEBUG: cls num  : 7, elapsed : 0.03212404251098633\n",
      "[2024/09/14 11:10:57] ppocr DEBUG: rec_res num  : 7, elapsed : 0.5664801597595215\n",
      "[2024/09/14 11:10:57] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.16255569458007812\n",
      "[2024/09/14 11:10:58] ppocr DEBUG: cls num  : 4, elapsed : 0.021373748779296875\n",
      "[2024/09/14 11:10:58] ppocr DEBUG: rec_res num  : 4, elapsed : 0.11573266983032227\n",
      "[2024/09/14 11:10:58] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.17829513549804688\n",
      "[2024/09/14 11:10:58] ppocr DEBUG: cls num  : 13, elapsed : 0.020391464233398438\n",
      "[2024/09/14 11:10:58] ppocr DEBUG: rec_res num  : 13, elapsed : 0.5009000301361084\n",
      "[2024/09/14 11:10:59] ppocr DEBUG: dt_boxes num : 24, elapsed : 0.16864323616027832\n",
      "[2024/09/14 11:10:59] ppocr DEBUG: cls num  : 24, elapsed : 0.029032230377197266\n",
      "[2024/09/14 11:10:59] ppocr DEBUG: rec_res num  : 24, elapsed : 0.5215747356414795\n",
      "[2024/09/14 11:10:59] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.16306710243225098\n",
      "[2024/09/14 11:10:59] ppocr DEBUG: cls num  : 13, elapsed : 0.01905035972595215\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: rec_res num  : 13, elapsed : 0.36523985862731934\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.1620168685913086\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: cls num  : 7, elapsed : 0.028202295303344727\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: rec_res num  : 7, elapsed : 0.1799910068511963\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.17283868789672852\n",
      "[2024/09/14 11:11:00] ppocr DEBUG: cls num  : 10, elapsed : 0.03683304786682129\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: rec_res num  : 10, elapsed : 0.43742990493774414\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.16932892799377441\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: cls num  : 5, elapsed : 0.012992143630981445\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: rec_res num  : 5, elapsed : 0.189774751663208\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.12334704399108887\n",
      "[2024/09/14 11:11:01] ppocr DEBUG: cls num  : 10, elapsed : 0.023195505142211914\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: rec_res num  : 10, elapsed : 0.3764472007751465\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.1699206829071045\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: cls num  : 2, elapsed : 0.00922846794128418\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: rec_res num  : 2, elapsed : 0.06927347183227539\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.16393733024597168\n",
      "[2024/09/14 11:11:02] ppocr DEBUG: cls num  : 14, elapsed : 0.021445274353027344\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: rec_res num  : 14, elapsed : 1.6417782306671143\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.18038678169250488\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: cls num  : 3, elapsed : 0.018128156661987305\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: rec_res num  : 3, elapsed : 0.14056110382080078\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.19464850425720215\n",
      "[2024/09/14 11:11:04] ppocr DEBUG: cls num  : 8, elapsed : 0.015419960021972656\n",
      "[2024/09/14 11:11:05] ppocr DEBUG: rec_res num  : 8, elapsed : 0.3210785388946533\n",
      "[2024/09/14 11:11:05] ppocr DEBUG: dt_boxes num : 34, elapsed : 0.2349390983581543\n",
      "[2024/09/14 11:11:05] ppocr DEBUG: cls num  : 34, elapsed : 0.05496525764465332\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: rec_res num  : 34, elapsed : 0.9232425689697266\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.17466163635253906\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: cls num  : 2, elapsed : 0.005365610122680664\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: rec_res num  : 2, elapsed : 0.07448172569274902\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.17720818519592285\n",
      "[2024/09/14 11:11:06] ppocr DEBUG: cls num  : 3, elapsed : 0.008271455764770508\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: rec_res num  : 3, elapsed : 0.0970163345336914\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.20575547218322754\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: cls num  : 2, elapsed : 0.0055239200592041016\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: rec_res num  : 2, elapsed : 0.05702638626098633\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: dt_boxes num : 28, elapsed : 0.1449413299560547\n",
      "[2024/09/14 11:11:07] ppocr DEBUG: cls num  : 28, elapsed : 0.03878283500671387\n",
      "[2024/09/14 11:11:09] ppocr DEBUG: rec_res num  : 28, elapsed : 2.2622458934783936\n",
      "[2024/09/14 11:11:10] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.236588716506958\n",
      "[2024/09/14 11:11:10] ppocr DEBUG: cls num  : 6, elapsed : 0.010697603225708008\n",
      "[2024/09/14 11:11:10] ppocr DEBUG: rec_res num  : 6, elapsed : 0.27133870124816895\n",
      "[2024/09/14 11:11:10] ppocr DEBUG: dt_boxes num : 15, elapsed : 0.17317438125610352\n",
      "[2024/09/14 11:11:10] ppocr DEBUG: cls num  : 15, elapsed : 0.03607439994812012\n",
      "[2024/09/14 11:11:11] ppocr DEBUG: rec_res num  : 15, elapsed : 0.5117721557617188\n",
      "[2024/09/14 11:11:11] ppocr DEBUG: dt_boxes num : 53, elapsed : 0.19029974937438965\n",
      "[2024/09/14 11:11:11] ppocr DEBUG: cls num  : 53, elapsed : 0.07489633560180664\n",
      "[2024/09/14 11:11:14] ppocr DEBUG: rec_res num  : 53, elapsed : 3.0486948490142822\n",
      "[2024/09/14 11:11:14] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.12410640716552734\n",
      "[2024/09/14 11:11:14] ppocr DEBUG: cls num  : 9, elapsed : 0.028370141983032227\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: rec_res num  : 9, elapsed : 0.2478199005126953\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.18959283828735352\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: cls num  : 3, elapsed : 0.009810686111450195\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: rec_res num  : 3, elapsed : 0.08050155639648438\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.2220439910888672\n",
      "[2024/09/14 11:11:15] ppocr DEBUG: cls num  : 12, elapsed : 0.01786494255065918\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: rec_res num  : 12, elapsed : 0.662794828414917\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.16142582893371582\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: cls num  : 3, elapsed : 0.009022235870361328\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: rec_res num  : 3, elapsed : 0.07842803001403809\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.16371870040893555\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: cls num  : 6, elapsed : 0.010469675064086914\n",
      "[2024/09/14 11:11:16] ppocr DEBUG: rec_res num  : 6, elapsed : 0.14362645149230957\n",
      "[2024/09/14 11:11:17] ppocr DEBUG: dt_boxes num : 17, elapsed : 0.2115490436553955\n",
      "[2024/09/14 11:11:17] ppocr DEBUG: cls num  : 17, elapsed : 0.037157535552978516\n",
      "[2024/09/14 11:11:17] ppocr DEBUG: rec_res num  : 17, elapsed : 0.4308195114135742\n",
      "[2024/09/14 11:11:17] ppocr DEBUG: dt_boxes num : 24, elapsed : 0.16735243797302246\n",
      "[2024/09/14 11:11:17] ppocr DEBUG: cls num  : 24, elapsed : 0.030695438385009766\n",
      "[2024/09/14 11:11:18] ppocr DEBUG: rec_res num  : 24, elapsed : 0.5855429172515869\n",
      "[2024/09/14 11:11:18] ppocr DEBUG: dt_boxes num : 27, elapsed : 0.1790001392364502\n",
      "[2024/09/14 11:11:18] ppocr DEBUG: cls num  : 27, elapsed : 0.040143489837646484\n",
      "[2024/09/14 11:11:19] ppocr DEBUG: rec_res num  : 27, elapsed : 0.7490317821502686\n",
      "[2024/09/14 11:11:19] ppocr DEBUG: dt_boxes num : 24, elapsed : 0.16867542266845703\n",
      "[2024/09/14 11:11:19] ppocr DEBUG: cls num  : 24, elapsed : 0.03062725067138672\n",
      "[2024/09/14 11:11:20] ppocr DEBUG: rec_res num  : 24, elapsed : 0.9323127269744873\n",
      "[2024/09/14 11:11:20] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.16766142845153809\n",
      "[2024/09/14 11:11:20] ppocr DEBUG: cls num  : 7, elapsed : 0.02754807472229004\n",
      "[2024/09/14 11:11:21] ppocr DEBUG: rec_res num  : 7, elapsed : 0.3555600643157959\n",
      "[2024/09/14 11:11:21] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.16513562202453613\n",
      "[2024/09/14 11:11:21] ppocr DEBUG: cls num  : 13, elapsed : 0.02495551109313965\n",
      "[2024/09/14 11:11:22] ppocr DEBUG: rec_res num  : 13, elapsed : 0.8268105983734131\n",
      "[2024/09/14 11:11:22] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.18715691566467285\n",
      "[2024/09/14 11:11:22] ppocr DEBUG: cls num  : 14, elapsed : 0.02518010139465332\n",
      "[2024/09/14 11:11:22] ppocr DEBUG: rec_res num  : 14, elapsed : 0.45241498947143555\n",
      "[2024/09/14 11:11:23] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.17377114295959473\n",
      "[2024/09/14 11:11:23] ppocr DEBUG: cls num  : 4, elapsed : 0.019700288772583008\n",
      "[2024/09/14 11:11:23] ppocr DEBUG: rec_res num  : 4, elapsed : 0.12039470672607422\n",
      "[2024/09/14 11:11:23] ppocr DEBUG: dt_boxes num : 15, elapsed : 0.22670865058898926\n",
      "[2024/09/14 11:11:23] ppocr DEBUG: cls num  : 15, elapsed : 0.035742998123168945\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: rec_res num  : 15, elapsed : 0.5990562438964844\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: dt_boxes num : 11, elapsed : 0.16407108306884766\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: cls num  : 11, elapsed : 0.02951216697692871\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: rec_res num  : 11, elapsed : 0.2891566753387451\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: dt_boxes num : 29, elapsed : 0.1736440658569336\n",
      "[2024/09/14 11:11:24] ppocr DEBUG: cls num  : 29, elapsed : 0.0391993522644043\n",
      "[2024/09/14 11:11:25] ppocr DEBUG: rec_res num  : 29, elapsed : 0.8614318370819092\n",
      "[2024/09/14 11:11:26] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.17255306243896484\n",
      "[2024/09/14 11:11:26] ppocr DEBUG: cls num  : 2, elapsed : 0.00919032096862793\n",
      "[2024/09/14 11:11:26] ppocr DEBUG: rec_res num  : 2, elapsed : 0.08042073249816895\n",
      "[2024/09/14 11:11:26] ppocr DEBUG: dt_boxes num : 22, elapsed : 0.1822185516357422\n",
      "[2024/09/14 11:11:26] ppocr DEBUG: cls num  : 22, elapsed : 0.04473090171813965\n",
      "[2024/09/14 11:11:27] ppocr DEBUG: rec_res num  : 22, elapsed : 0.6885678768157959\n",
      "[2024/09/14 11:11:27] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.17604494094848633\n",
      "[2024/09/14 11:11:27] ppocr DEBUG: cls num  : 13, elapsed : 0.03806614875793457\n",
      "[2024/09/14 11:11:27] ppocr DEBUG: rec_res num  : 13, elapsed : 0.49115562438964844\n",
      "[2024/09/14 11:11:27] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.17774200439453125\n",
      "[2024/09/14 11:11:28] ppocr DEBUG: cls num  : 13, elapsed : 0.023456573486328125\n",
      "[2024/09/14 11:11:28] ppocr DEBUG: rec_res num  : 13, elapsed : 0.7113971710205078\n",
      "[2024/09/14 11:11:28] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.17304420471191406\n",
      "[2024/09/14 11:11:28] ppocr DEBUG: cls num  : 6, elapsed : 0.010371208190917969\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: rec_res num  : 6, elapsed : 0.30310869216918945\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.17978286743164062\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: cls num  : 8, elapsed : 0.01827549934387207\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: rec_res num  : 8, elapsed : 0.2374591827392578\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: dt_boxes num : 18, elapsed : 0.16662096977233887\n",
      "[2024/09/14 11:11:29] ppocr DEBUG: cls num  : 18, elapsed : 0.02407526969909668\n",
      "[2024/09/14 11:11:30] ppocr DEBUG: rec_res num  : 18, elapsed : 0.5456516742706299\n",
      "[2024/09/14 11:11:30] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.16457056999206543\n",
      "[2024/09/14 11:11:30] ppocr DEBUG: cls num  : 14, elapsed : 0.022418737411499023\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: rec_res num  : 14, elapsed : 0.40340495109558105\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.16104412078857422\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: cls num  : 4, elapsed : 0.020348310470581055\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: rec_res num  : 4, elapsed : 0.3796858787536621\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.1628129482269287\n",
      "[2024/09/14 11:11:31] ppocr DEBUG: cls num  : 12, elapsed : 0.017459869384765625\n",
      "[2024/09/14 11:11:33] ppocr DEBUG: rec_res num  : 12, elapsed : 2.0912301540374756\n",
      "[2024/09/14 11:11:34] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.16952848434448242\n",
      "[2024/09/14 11:11:34] ppocr DEBUG: cls num  : 3, elapsed : 0.02587604522705078\n",
      "[2024/09/14 11:11:34] ppocr DEBUG: rec_res num  : 3, elapsed : 0.1082913875579834\n",
      "Results saved to output_paddleocr.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "process_images_paddleocr(\"stratified_sample.csv\", \"downloaded_images\", \"output_paddleocr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772eaa70",
   "metadata": {},
   "source": [
    "## docTR-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49968643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Solutions/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18df4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the docTR OCR predictor with PyTorch backend\n",
    "ocr_model_doctr = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b5cfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_doctr(image_path):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        \n",
    "        # Load the image into docTR for OCR\n",
    "        document = DocumentFile.from_images([image_path])\n",
    "        result = ocr_model_doctr(document)\n",
    "        \n",
    "        # Extract text from docTR's result\n",
    "        extracted_text = []\n",
    "        for block in result.pages[0].blocks:\n",
    "            for line in block.lines:\n",
    "                for word_obj in line.words:\n",
    "                    extracted_text.append(word_obj.value)  # Extract the text from Word object\n",
    "        \n",
    "        return ' '.join(extracted_text).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"docTR OCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c69edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_doctr(stratified_sample_file, download_folder, output_file):\n",
    "    # Load the stratified sample dataset\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    \n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    # Extract text using docTR\n",
    "    print(\"Extracting text using docTR...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_doctr(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up downloaded images\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    # Save the results to the output file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ead1e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 83088.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using docTR...\n",
      "Results saved to output_doctr.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "process_images_doctr(\"stratified_sample.csv\", \"downloaded_images\", \"output_doctr.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2afc8",
   "metadata": {},
   "source": [
    "## Rapid-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c922b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 99.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using RapidOCR...\n",
      "Results saved to output_rapidocr.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from rapidocr_onnxruntime import RapidOCR\n",
    "\n",
    "# Initialize RapidOCR\n",
    "ocr_rapidocr = RapidOCR()\n",
    "\n",
    "# Preprocessing function for images\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        # Read and preprocess the image\n",
    "        image = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        processed_image = cv2.medianBlur(thresh, 3)\n",
    "        return processed_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract text using RapidOCR\n",
    "def extract_text_rapidocr(image_path):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        if preprocessed_image is None:\n",
    "            return \"\"\n",
    "        \n",
    "        # Perform OCR using RapidOCR\n",
    "        result, _ = ocr_rapidocr(image_path)  # Use original image path, not preprocessed\n",
    "\n",
    "        # Check if result is None or empty\n",
    "        if not result or result is None:\n",
    "            return \"\"\n",
    "\n",
    "        # Extract text from the result\n",
    "        extracted_text = ' '.join([text[1][0] for text in result if text[1]])  # Safeguard for None values\n",
    "        return extracted_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"RapidOCR extraction failed for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to process images and extract text\n",
    "def process_images_rapidocr(stratified_sample_file, download_folder, output_file):\n",
    "    # Load the stratified sample dataset\n",
    "    df = pd.read_csv(stratified_sample_file)\n",
    "    \n",
    "    print(\"Downloading images...\")\n",
    "    download_images(df['image_link'], download_folder)\n",
    "    \n",
    "    print(\"Extracting text using RapidOCR...\")\n",
    "    df['Extracted'] = df['image_link'].apply(lambda link: extract_text_rapidocr(os.path.join(download_folder, os.path.basename(link))))\n",
    "    \n",
    "    # Clean up downloaded images\n",
    "    for file in os.listdir(download_folder):\n",
    "        os.remove(os.path.join(download_folder, file))\n",
    "    \n",
    "    # Save the results to the output file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Usage\n",
    "process_images_rapidocr(\"stratified_sample.csv\", \"downloaded_images\", \"output_rapidocr.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
